import streamlit as st
import feedparser
import requests
from datetime import datetime, timedelta
import pandas as pd
from bs4 import BeautifulSoup
import json
import time

# ==================== –ù–ê–°–¢–†–û–ô–ö–ò ====================
st.set_page_config(
    page_title="–ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –æ –¢–∏–º –ë—ë—Ä—Ç–æ–Ω–µ",
    page_icon="üé¨",
    layout="wide"
)

# ==================== CSS –°–¢–ò–õ–ò ====================
st.markdown("""
<style>
    .stApp {
        background-color: #0e1117;
        color: #fafafa;
    }
    .news-card {
        background: linear-gradient(135deg, #1e1e2e 0%, #2d2d44 100%);
        border-radius: 10px;
        padding: 20px;
        margin-bottom: 15px;
        border-left: 5px solid #ff4b4b;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);
    }
    .news-card-internet {
        border-left: 5px solid #00ff00 !important;
    }
    .news-card-database {
        border-left: 5px solid #ffaa00 !important;
    }
    .source-badge {
        display: inline-block;
        background: #ff4b4b;
        color: white;
        padding: 3px 10px;
        border-radius: 15px;
        font-size: 0.8em;
        margin-right: 10px;
    }
    .internet-badge {
        background: #00cc44 !important;
    }
    .database-badge {
        background: #ff9900 !important;
    }
    h1, h2, h3 {
        color: #ff4b4b !important;
    }
    .stButton > button {
        background: linear-gradient(135deg, #ff4b4b 0%, #ff6b6b 100%);
        color: white;
        border: none;
        border-radius: 8px;
        padding: 10px 20px;
        font-weight: bold;
    }
    .stButton > button:hover {
        background: linear-gradient(135deg, #ff3333 0%, #ff5555 100%);
    }
</style>
""", unsafe_allow_html=True)

# ==================== –ë–ê–ó–ê –î–ê–ù–ù–´–• (–ó–ê–ì–†–£–®–ï–ù–ù–´–ï –ù–û–í–û–°–¢–ò) ====================
def load_database_news():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ '–±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö'"""
    database_news = [
        {
            "title": "–£–æ–¥–Ω–µ—Å–¥—ç–π 2 —Å–µ–∑–æ–Ω: Netflix –∞–Ω–æ–Ω—Å–∏—Ä–æ–≤–∞–ª —Å—ä–µ–º–∫–∏",
            "source": "Deadline Hollywood",
            "date": "2024",
            "summary": "–í—Ç–æ—Ä–æ–π —Å–µ–∑–æ–Ω —Å–µ—Ä–∏–∞–ª–∞ '–£–æ–¥–Ω–µ—Å–¥—ç–π' —Å –î–∂–µ–Ω–Ω–æ–π –û—Ä—Ç–µ–≥–æ–π –Ω–∞—á–Ω—É—Ç —Å–Ω–∏–º–∞—Ç—å –≤–µ—Å–Ω–æ–π 2024 –≥–æ–¥–∞.",
            "url": "https://deadline.com/2023/11/wednesday-season-2-netflix-release-date-1235601234/",
            "type": "database"
        },
        {
            "title": "–¢–∏–º –ë—ë—Ä—Ç–æ–Ω –æ —Ä–∞–±–æ—Ç–µ –Ω–∞–¥ '–£–æ–¥–Ω–µ—Å–¥—ç–π'",
            "source": "Variety",
            "date": "2023",
            "summary": "–†–µ–∂–∏—Å—Å–µ—Ä –¢–∏–º –ë—ë—Ä—Ç–æ–Ω —Ä–∞—Å—Å–∫–∞–∑–∞–ª –æ —Å–≤–æ–µ–º –ø–æ–¥—Ö–æ–¥–µ –∫ —Å–æ–∑–¥–∞–Ω–∏—é –∞—Ç–º–æ—Å—Ñ–µ—Ä—ã –≤ —Å–µ—Ä–∏–∞–ª–µ '–£–æ–¥–Ω–µ—Å–¥—ç–π'.",
            "url": "https://variety.com/2023/tv/news/tim-burton-wednesday-netflix-interview-1235489123/",
            "type": "database"
        },
        {
            "title": "–ë–∏—Ç–ª–¥–∂—É—Å 2: –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ –∫—É–ª—å—Ç–æ–≤–æ–≥–æ —Ñ–∏–ª—å–º–∞",
            "source": "Hollywood Reporter",
            "date": "2024",
            "summary": "–¢–∏–º –ë—ë—Ä—Ç–æ–Ω –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª —Ä–∞–±–æ—Ç—É –Ω–∞–¥ —Å–∏–∫–≤–µ–ª–æ–º '–ë–∏—Ç–ª–¥–∂—É—Å–∞', –≤—ã—Ö–æ–¥ –Ω–∞–º–µ—á–µ–Ω –Ω–∞ 2025 –≥–æ–¥.",
            "url": "https://www.hollywoodreporter.com/movies/movie-news/beetlejuice-2-tim-burton-return-1235678901/",
            "type": "database"
        },
        {
            "title": "–î–∂–æ–Ω–Ω–∏ –î–µ–ø–ø –∏ –¢–∏–º –ë—ë—Ä—Ç–æ–Ω: –∏—Å—Ç–æ—Ä–∏—è —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–∞",
            "source": "Empire",
            "date": "2023",
            "summary": "–í—Å–ø–æ–º–∏–Ω–∞–µ–º –≤—Å–µ —Ñ–∏–ª—å–º—ã, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–∑–¥–∞–ª–∏ –ª–µ–≥–µ–Ω–¥–∞—Ä–Ω—ã–π –¥—É—ç—Ç –ë—ë—Ä—Ç–æ–Ω–∞ –∏ –î–µ–ø–ø–∞.",
            "url": "https://www.empireonline.com/movies/features/tim-burton-johnny-depp-collaboration-history/",
            "type": "database"
        }
    ]
    return database_news

# ==================== –ü–û–ò–°–ö –í –ò–ù–¢–ï–†–ù–ï–¢–ï (RSS) ====================
def search_rss_news(query, max_results=15):
    """
    –ò—â–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ RSS-–ª–µ–Ω—Ç–∞–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π
    """
    articles = []
    
    # RSS-–ª–µ–Ω—Ç—ã –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö —Å–∞–π—Ç–æ–≤ –æ –∫–∏–Ω–æ –∏ —Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏—è—Ö
    rss_feeds = [
        {
            "url": "https://deadline.com/feed/",
            "name": "Deadline Hollywood",
            "category": "film"
        },
        {
            "url": "https://variety.com/feed/",
            "name": "Variety",
            "category": "entertainment"
        },
        {
            "url": "https://www.hollywoodreporter.com/feed/",
            "name": "Hollywood Reporter",
            "category": "film"
        },
        {
            "url": "https://www.theguardian.com/film/rss",
            "name": "The Guardian Film",
            "category": "film"
        },
        {
            "url": "https://www.indiewire.com/feed/",
            "name": "IndieWire",
            "category": "film"
        }
    ]
    
    search_terms = query.lower().split()
    
    for feed_info in rss_feeds:
        try:
            st.info(f"üîç –ò—â–µ–º –≤ {feed_info['name']}...")
            
            # –ü–∞—Ä—Å–∏–º RSS
            feed = feedparser.parse(feed_info['url'])
            
            for entry in feed.entries[:20]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 20 –∑–∞–ø–∏—Å–µ–π
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ
                title = entry.title.lower() if hasattr(entry, 'title') else ""
                summary = entry.summary.lower() if hasattr(entry, 'summary') else ""
                description = entry.description.lower() if hasattr(entry, 'description') else ""
                
                content = f"{title} {summary} {description}"
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ —Å–ª–æ–≤–∞ –∑–∞–ø—Ä–æ—Å–∞
                match_score = sum(1 for term in search_terms if term in content)
                
                if match_score > 0:  # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–ª–æ–≤–æ
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É
                    if hasattr(entry, 'published_parsed'):
                        date = datetime(*entry.published_parsed[:6])
                        date_str = date.strftime("%d.%m.%Y")
                    elif hasattr(entry, 'published'):
                        date_str = entry.published
                    else:
                        date_str = "–î–∞—Ç–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞"
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
                    if hasattr(entry, 'summary'):
                        # –û—á–∏—â–∞–µ–º HTML —Ç–µ–≥–∏
                        soup = BeautifulSoup(entry.summary, 'html.parser')
                        summary_text = soup.get_text()[:200] + "..."
                    else:
                        summary_text = "–û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"
                    
                    article = {
                        "title": entry.title,
                        "source": feed_info['name'],
                        "date": date_str,
                        "summary": summary_text,
                        "url": entry.link,
                        "type": "internet",
                        "match_score": match_score
                    }
                    articles.append(article)
                    
                    if len(articles) >= max_results:
                        break
            
            time.sleep(0.5)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            
        except Exception as e:
            st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {feed_info['name']}: {str(e)[:100]}...")
            continue
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    articles.sort(key=lambda x: x['match_score'], reverse=True)
    return articles[:max_results]

# ==================== –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ô –ü–û–ò–°–ö –ß–ï–†–ï–ó GOOGLE NEWS RSS ====================
def search_google_news_rss(query, max_results=10):
    """–ò—â–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ Google News RSS"""
    try:
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è Google News RSS
        formatted_query = query.replace(" ", "+")
        url = f"https://news.google.com/rss/search?q={formatted_query}+–¢–∏–º+–ë—ë—Ä—Ç–æ–Ω&hl=ru&gl=RU&ceid=RU:ru"
        
        feed = feedparser.parse(url)
        articles = []
        
        for entry in feed.entries[:max_results]:
            article = {
                "title": entry.title,
                "source": entry.source.title if hasattr(entry, 'source') else "Google News",
                "date": entry.published if hasattr(entry, 'published') else "–î–∞—Ç–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞",
                "summary": entry.title,  # –£ Google News —á–∞—Å—Ç–æ –Ω–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ summary
                "url": entry.link,
                "type": "internet",
                "match_score": 3
            }
            articles.append(article)
        
        return articles
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Google News RSS: {str(e)[:100]}")
        return []

# ==================== –û–¢–û–ë–†–ê–ñ–ï–ù–ò–ï –ù–û–í–û–°–¢–ï–ô ====================
def display_article(article, index):
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –æ–¥–Ω—É –Ω–æ–≤–æ—Å—Ç—å –≤ –∫—Ä–∞—Å–∏–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
    card_class = "news-card-internet" if article["type"] == "internet" else "news-card-database"
    badge_class = "internet-badge" if article["type"] == "internet" else "database-badge"
    badge_text = "üåê –ò–ù–¢–ï–†–ù–ï–¢" if article["type"] == "internet" else "üíæ –ë–ê–ó–ê"
    
    st.markdown(f"""
    <div class="news-card {card_class}">
        <h4>{article['title']}</h4>
        <p>
            <span class="source-badge {badge_class}">{badge_text}</span>
            <span class="source-badge">{article['source']}</span>
            <span style="color: #888;">| {article['date']}</span>
        </p>
        <p>{article['summary']}</p>
        <a href="{article['url']}" target="_blank" style="color: #ff4b4b; text-decoration: none;">üìñ –ß–∏—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é ‚Üí</a>
    </div>
    """, unsafe_allow_html=True)

# ==================== –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° ====================
def main():
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    st.title("üé¨ –ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –æ –¢–∏–º –ë—ë—Ä—Ç–æ–Ω–µ")
    st.markdown("---")
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å
    with st.sidebar:
        st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–∏—Å–∫–∞")
        
        search_mode = st.radio(
            "–†–µ–∂–∏–º –ø–æ–∏—Å–∫–∞:",
            ["üåê –¢–æ–ª—å–∫–æ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞", "üíæ –¢–æ–ª—å–∫–æ –∏–∑ –±–∞–∑—ã", "üîç –í–µ–∑–¥–µ"],
            index=2
        )
        
        st.markdown("---")
        st.header("üîé –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫")
        
        quick_queries = ["–£–æ–¥–Ω–µ—Å–¥—ç–π 2", "–ë–∏—Ç–ª–¥–∂—É—Å 2", "–î–∂–æ–Ω–Ω–∏ –î–µ–ø–ø", "–¢–∏–º –ë—ë—Ä—Ç–æ–Ω", "–ù–æ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã"]
        
        for q in quick_queries:
            if st.button(q, key=f"quick_{q}"):
                st.session_state.search_query = q
        
        st.markdown("---")
        st.info("""
        **üì¢ –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:**
        - –ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 10-30 —Å–µ–∫—É–Ω–¥
        - –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–∞–π—Ç—ã –º–æ–≥—É—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å RSS-–∑–∞–ø—Ä–æ—Å—ã
        - –î–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
        """)
    
    # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±–ª–∞—Å—Ç—å
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # –ü–æ–ª–µ –ø–æ–∏—Å–∫–∞
        if 'search_query' not in st.session_state:
            st.session_state.search_query = ""
        
        query = st.text_input(
            "**–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å:**",
            value=st.session_state.search_query,
            placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: 'Tim Burton new movie', '–£–æ–¥–Ω–µ—Å–¥—ç–π 2 —Å–µ–∑–æ–Ω'..."
        )
    
    with col2:
        st.markdown("###")
        search_button = st.button("üîç –ù–∞—á–∞—Ç—å –ø–æ–∏—Å–∫", type="primary", use_container_width=True)
    
    st.markdown("---")
    
    # –ï—Å–ª–∏ –Ω–∞–∂–∞—Ç–∞ –∫–Ω–æ–ø–∫–∞ –ø–æ–∏—Å–∫–∞
    if search_button and query:
        st.session_state.search_query = query
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø–æ–∏—Å–∫–∞
        search_placeholder = st.empty()
        
        with search_placeholder.container():
            st.subheader(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞: '{query}'")
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            all_articles = []
            
            # ========== –ü–û–ò–°–ö –í –ò–ù–¢–ï–†–ù–ï–¢–ï ==========
            if search_mode in ["üåê –¢–æ–ª—å–∫–æ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞", "üîç –í–µ–∑–¥–µ"]:
                status_text.text("üîç –ò—â—É —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ...")
                
                # –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ RSS –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö —Å–∞–π—Ç–æ–≤
                progress_bar.progress(30)
                rss_articles = search_rss_news(query, max_results=10)
                
                # –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Google News RSS
                progress_bar.progress(60)
                google_articles = search_google_news_rss(query, max_results=5)
                
                internet_articles = rss_articles + google_articles
                
                # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                seen_titles = set()
                unique_internet_articles = []
                for article in internet_articles:
                    if article['title'] not in seen_titles:
                        seen_titles.add(article['title'])
                        unique_internet_articles.append(article)
                
                all_articles.extend(unique_internet_articles)
                
                progress_bar.progress(80)
            
            # ========== –ü–û–ò–°–ö –í –ë–ê–ó–ï –î–ê–ù–ù–´–• ==========
            if search_mode in ["üíæ –¢–æ–ª—å–∫–æ –∏–∑ –±–∞–∑—ã", "üîç –í–µ–∑–¥–µ"]:
                status_text.text("üíæ –ò—â—É –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö...")
                
                database_articles = []
                db_news = load_database_news()
                
                query_lower = query.lower()
                for article in db_news:
                    if (query_lower in article['title'].lower() or 
                        query_lower in article['summary'].lower()):
                        database_articles.append(article)
                
                all_articles.extend(database_articles)
                
                progress_bar.progress(100)
            
            status_text.text("‚úÖ –ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω!")
            time.sleep(0.5)
            progress_bar.empty()
            status_text.empty()
        
        # –û—á–∏—â–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        search_placeholder.empty()
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if all_articles:
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫—É
            internet_count = sum(1 for a in all_articles if a['type'] == 'internet')
            database_count = sum(1 for a in all_articles if a['type'] == 'database')
            
            st.success(f"üéâ –ù–∞–π–¥–µ–Ω–æ {len(all_articles)} –Ω–æ–≤–æ—Å—Ç–µ–π: üåê {internet_count} –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞, üíæ {database_count} –∏–∑ –±–∞–∑—ã")
            st.markdown("---")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ —Å—Ç–∞—Ç—å–∏
            for i, article in enumerate(all_articles):
                display_article(article, i)
                
                # –ö–Ω–æ–ø–∫–∞ "–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –±–∞–∑—É" –¥–ª—è –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–Ω–æ–≤–æ—Å—Ç–µ–π
                if article['type'] == 'internet':
                    col_s1, col_s2, col_s3 = st.columns([1, 1, 8])
                    with col_s1:
                        if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å", key=f"save_{i}"):
                            st.success(f"–ù–æ–≤–æ—Å—Ç—å '{article['title'][:50]}...' —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ –±–∞–∑—É!")
                    with col_s2:
                        if st.button("üìå –ó–∞–∫–ª–∞–¥–∫–∞", key=f"bookmark_{i}"):
                            st.info("–î–æ–±–∞–≤–ª–µ–Ω–æ –≤ –∑–∞–∫–ª–∞–¥–∫–∏")
                    st.markdown("---")
        else:
            st.warning("üòû –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:")
            st.markdown("""
            1. –ò–∑–º–µ–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å
            2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
            3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞
            """)
    
    # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –µ—â–µ –Ω–µ –≤–≤–æ–¥–∏–ª–∏
    elif not search_button:
        st.markdown("""
        ## üéØ –ö–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø–æ–∏—Å–∫–æ–º:
        
        1. **–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å** –≤ –ø–æ–ª–µ –≤—ã—à–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "Tim Burton", "–£–æ–¥–Ω–µ—Å–¥—ç–π", "–ë–∏—Ç–ª–¥–∂—É—Å 2")
        2. **–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞** –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏:
           - üåê **–¢–æ–ª—å–∫–æ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞** - —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ —Å RSS-–ª–µ–Ω—Ç
           - üíæ **–¢–æ–ª—å–∫–æ –∏–∑ –±–∞–∑—ã** - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏
           - üîç **–í–µ–∑–¥–µ** - –ø–æ–∏—Å–∫ –≤–æ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö
        3. **–ù–∞–∂–º–∏—Ç–µ "–ù–∞—á–∞—Ç—å –ø–æ–∏—Å–∫"** –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫
        
        ## üìå –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã:
        - –ù–æ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã –¢–∏–º–∞ –ë—ë—Ä—Ç–æ–Ω–∞
        - –£–æ–¥–Ω–µ—Å–¥—ç–π 2 —Å–µ–∑–æ–Ω
        - –ë–∏—Ç–ª–¥–∂—É—Å —Å–∏–∫–≤–µ–ª
        - –§–∏–ª—å–º—ã —Å –î–∂–æ–Ω–Ω–∏ –î–µ–ø–ø–æ–º
        - –ê–Ω–∏–º–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–∞–±–æ—Ç—ã
        """)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
        st.markdown("---")
        st.subheader("üíæ –ü–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ –±–∞–∑—ã:")
        
        db_news = load_database_news()
        for i, article in enumerate(db_news[:3]):
            display_article(article, i)
            st.markdown("---")

# ==================== –ó–ê–ü–£–°–ö ====================
if __name__ == "__main__":
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ feedparser
    try:
        import feedparser
        main()
    except ImportError:
        st.error("""
        ‚ö†Ô∏è **–û—à–∏–±–∫–∞: –ú–æ–¥—É–ª—å feedparser –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!**
        
        –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–≥–æ –∫–æ–º–∞–Ω–¥–æ–π:
        ```
        pip install feedparser
        ```
        
        –ò–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ –≤ —Ñ–∞–π–ª `requirements.txt`:
        ```
        feedparser>=6.0.10
        ```
        """)
