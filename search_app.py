import streamlit as st
import feedparser
import requests
from datetime import datetime, timedelta
import time
from bs4 import BeautifulSoup

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–¢–∏–º –ë—ë—Ä—Ç–æ–Ω - –ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π", 
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("üßõ –†–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π: –¢–∏–º –ë—ë—Ä—Ç–æ–Ω")
st.markdown("### –ü–æ–∏—Å–∫ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ")

# ========== –ë–û–ö–û–í–ê–Ø –ü–ê–ù–ï–õ–¨ ==========
with st.sidebar:
    st.title("üé¨ –¢–∏–º –ë—ë—Ä—Ç–æ–Ω")
    st.markdown("---")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–∏—Å–∫–∞
    st.header("‚öôÔ∏è –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π")
    st.write("–í—ã–±–µ—Ä–∏—Ç–µ, –≥–¥–µ –∏—Å–∫–∞—Ç—å –Ω–æ–≤–æ—Å—Ç–∏:")
    
    sources = {
        "BBC News": st.checkbox("BBC News", value=True),
        "The Guardian": st.checkbox("The Guardian", value=True),
        "Variety": st.checkbox("Variety", value=True),
        "Deadline": st.checkbox("Deadline Hollywood", value=True),
        "Hollywood Reporter": st.checkbox("Hollywood Reporter", value=True),
        "IndieWire": st.checkbox("IndieWire", value=True),
        "Google News": st.checkbox("Google News", value=True),
        "Entertainment Weekly": st.checkbox("Entertainment Weekly", value=False)
    }
    
    st.markdown("---")
    
    # –§–∏–ª—å—Ç—Ä—ã
    st.header("‚è≥ –§–∏–ª—å—Ç—Ä—ã")
    time_filter = st.selectbox(
        "–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞:",
        ["–ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π", "–ü–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü", "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 3 –º–µ—Å—è—Ü–∞", "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 6 –º–µ—Å—è—Ü–µ–≤", "–í—Å–µ –≤—Ä–µ–º—è"],
        index=0
    )
    
    # –í–°–ï–ì–î–ê –ú–ê–ö–°–ò–ú–£–ú
    st.info("‚ÑπÔ∏è –í—Å–µ–≥–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π")
    
    st.markdown("---")
    
    # –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫
    st.header("üöÄ –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫")
    st.write("–ù–∞–∂–º–∏—Ç–µ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞:")
    
    quick_queries = [
        "Wednesday season 2",
        "Beetlejuice 2",
        "Tim Burton",
        "Johnny Depp",
        "Monica Bellucci",
        "Burton exhibition",
        "New projects 2024",
        "Netflix Wednesday",
        "Jenna Ortega",
        "Winona Ryder"
    ]
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫–∏ –≤ 2 –∫–æ–ª–æ–Ω–∫–∏
    cols = st.columns(2)
    for idx, query in enumerate(quick_queries):
        col = cols[idx % 2]
        with col:
            if st.button(f"üîç {query}", key=f"quick_{query}", use_container_width=True):
                st.session_state.search_query = query
                st.rerun()
    
    st.markdown("---")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    st.header("‚ÑπÔ∏è –û –ø–æ–∏—Å–∫–µ")
    st.info("""
    **–≠—Ç–æ —Ä–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π!**
    
    –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏—â–µ—Ç –≤ RSS-–ª–µ–Ω—Ç–∞—Ö:
    ‚Ä¢ BBC, Guardian, Variety
    ‚Ä¢ Deadline, Hollywood Reporter
    ‚Ä¢ Google News
    
    –í—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ ‚Äî —Ä–µ–∞–ª—å–Ω—ã–µ —Å—Ç–∞—Ç—å–∏
    —Å–æ —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏.
    """)

# ========== –§–£–ù–ö–¶–ò–ò –ü–û–ò–°–ö–ê –ù–û–í–û–°–¢–ï–ô ==========
def get_date_from_entry(entry):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞—Ç—É –∏–∑ –Ω–æ–≤–æ—Å—Ç–Ω–æ–π –∑–∞–ø–∏—Å–∏"""
    try:
        if hasattr(entry, 'published_parsed'):
            return datetime(*entry.published_parsed[:6])
        elif hasattr(entry, 'updated_parsed'):
            return datetime(*entry.updated_parsed[:6])
        elif hasattr(entry, 'published'):
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–∞—Ç
            date_str = entry.published
            formats = [
                "%a, %d %b %Y %H:%M:%S %Z",
                "%a, %d %b %Y %H:%M:%S %z",
                "%Y-%m-%dT%H:%M:%SZ",
                "%Y-%m-%d %H:%M:%S"
            ]
            for fmt in formats:
                try:
                    return datetime.strptime(date_str, fmt)
                except:
                    continue
    except:
        pass
    return datetime.now()

def filter_by_time(news_list, time_period):
    """–§–∏–ª—å—Ç—Ä—É–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏"""
    now = datetime.now()
    
    if time_period == "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π":
        cutoff = now - timedelta(days=7)
    elif time_period == "–ü–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü":
        cutoff = now - timedelta(days=30)
    elif time_period == "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 3 –º–µ—Å—è—Ü–∞":
        cutoff = now - timedelta(days=90)
    elif time_period == "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 6 –º–µ—Å—è—Ü–µ–≤":
        cutoff = now - timedelta(days=180)
    else:
        return news_list
    
    return [news for news in news_list if news['date'] >= cutoff]

def search_bbc_news(query):
    """–ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ BBC"""
    try:
        url = "https://feeds.bbci.co.uk/news/entertainment_and_arts/rss.xml"
        feed = feedparser.parse(url)
        
        results = []
        for entry in feed.entries:
            content = f"{entry.title} {entry.get('summary', '')}".lower()
            if query.lower() in content:
                results.append({
                    'title': entry.title,
                    'link': entry.link,
                    'source': 'BBC News',
                    'date': get_date_from_entry(entry),
                    'summary': entry.get('summary', '')[:250] + "..." if len(entry.get('summary', '')) > 250 else entry.get('summary', ''),
                    'full_text': entry.get('summary', '')
                })
        return results
    except Exception as e:
        return []

def search_guardian_news(query):
    """–ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ The Guardian"""
    try:
        url = "https://www.theguardian.com/film/rss"
        feed = feedparser.parse(url)
        
        results = []
        for entry in feed.entries:
            content = f"{entry.title} {entry.get('summary', '')}".lower()
            if query.lower() in content:
                try:
                    response = requests.get(entry.link, timeout=5)
                    soup = BeautifulSoup(response.text, 'html.parser')
                    
                    # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏ –≤ The Guardian
                    article_body = soup.find('div', {'data-gu-name': 'body'})
                    if not article_body:
                        article_body = soup.find('div', class_='article-body')
                    if not article_body:
                        article_body = soup.find('article')
                    
                    full_text = article_body.get_text()[:500] + "..." if article_body else entry.get('summary', '')[:300] + "..."
                except:
                    full_text = entry.get('summary', '')[:300] + "..."
                
                results.append({
                    'title': entry.title,
                    'link': entry.link,
                    'source': 'The Guardian',
                    'date': get_date_from_entry(entry),
                    'summary': entry.get('summary', '')[:200] + "..." if len(entry.get('summary', '')) > 200 else entry.get('summary', ''),
                    'full_text': full_text
                })
        return results
    except Exception as e:
        return []

def search_variety_news(query):
    """–ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ Variety"""
    try:
        url = "https://variety.com/feed/"
        feed = feedparser.parse(url)
        
        results = []
        for entry in feed.entries:
            content = f"{entry.title} {entry.get('summary', '')}".lower()
            if query.lower() in content:
                results.append({
                    'title': entry.title,
                    'link': entry.link,
                    'source': 'Variety',
                    'date': get_date_from_entry(entry),
                    'summary': entry.get('summary', '')[:250] + "..." if len(entry.get('summary', '')) > 250 else entry.get('summary', ''),
                    'full_text': entry.get('summary', '')
                })
        return results
    except:
        return []

def search_deadline_news(query):
    """–ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ Deadline"""
    try:
        url = "https://deadline.com/feed/"
        feed = feedparser.parse(url)
        
        results = []
        for entry in feed.entries:
            content = f"{entry.title} {entry.get('summary', '')}".lower()
            if query.lower() in content:
                results.append({
                    'title': entry.title,
                    'link': entry.link,
                    'source': 'Deadline Hollywood',
                    'date': get_date_from_entry(entry),
                    'summary': entry.get('summary', '')[:250] + "..." if len(entry.get('summary', '')) > 250 else entry.get('summary', ''),
                    'full_text': entry.get('summary', '')
                })
        return results
    except:
        return []

def search_hollywood_reporter(query):
    """–ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ Hollywood Reporter"""
    try:
        url = "https://www.hollywoodreporter.com/feed/"
        feed = feedparser.parse(url)
        
        results = []
        for entry in feed.entries:
            content = f"{entry.title} {entry.get('summary', '')}".lower()
            if query.lower() in content:
                results.append({
                    'title': entry.title,
                    'link': entry.link,
                    'source': 'Hollywood Reporter',
                    'date': get_date_from_entry(entry),
                    'summary': entry.get('summary', '')[:250] + "..." if len(entry.get('summary', '')) > 250 else entry.get('summary', ''),
                    'full_text': entry.get('summary', '')
                })
        return results
    except:
        return []

def search_indiewire(query):
    """–ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ IndieWire"""
    try:
        url = "https://www.indiewire.com/feed/"
        feed = feedparser.parse(url)
        
        results = []
        for entry in feed.entries:
            content = f"{entry.title} {entry.get('summary', '')}".lower()
            if query.lower() in content:
                results.append({
                    'title': entry.title,
                    'link': entry.link,
                    'source': 'IndieWire',
                    'date': get_date_from_entry(entry),
                    'summary': entry.get('summary', '')[:250] + "..." if len(entry.get('summary', '')) > 250 else entry.get('summary', ''),
                    'full_text': entry.get('summary', '')
                })
        return results
    except:
        return []

def search_google_news(query):
    """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Google News RSS"""
    try:
        search_query = query.replace(' ', '+')
        url = f"https://news.google.com/rss/search?q={search_query}+film+movie+Hollywood&hl=en-US&gl=US&ceid=US:en"
        
        feed = feedparser.parse(url)
        
        results = []
        for entry in feed.entries:
            results.append({
                'title': entry.title,
                'link': entry.link,
                'source': entry.source.title if hasattr(entry, 'source') else 'Google News',
                'date': get_date_from_entry(entry),
                'summary': entry.title[:150] + "..." if len(entry.title) > 150 else entry.title,
                'full_text': entry.title
            })
        return results
    except:
        return []

def search_all_news(query, enabled_sources):
    """–ò—â–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –≤—Å–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º - –í–°–ï–ì–î–ê –ú–ê–ö–°–ò–ú–£–ú"""
    all_results = []
    
    # –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    sources_funcs = [
        ("BBC News", search_bbc_news, enabled_sources.get("BBC News", False)),
        ("The Guardian", search_guardian_news, enabled_sources.get("The Guardian", False)),
        ("Variety", search_variety_news, enabled_sources.get("Variety", False)),
        ("Deadline", search_deadline_news, enabled_sources.get("Deadline", False)),
        ("Hollywood Reporter", search_hollywood_reporter, enabled_sources.get("Hollywood Reporter", False)),
        ("IndieWire", search_indiewire, enabled_sources.get("IndieWire", False)),
        ("Google News", search_google_news, enabled_sources.get("Google News", False)),
        ("Entertainment Weekly", search_google_news, enabled_sources.get("Entertainment Weekly", False))  # –∑–∞–≥–ª—É—à–∫–∞
    ]
    
    total_sources = sum(1 for _, _, enabled in sources_funcs if enabled)
    current_source = 0
    
    for source_name, func, enabled in sources_funcs:
        if enabled:
            current_source += 1
            progress = current_source / total_sources
            progress_bar.progress(progress)
            status_text.text(f"üîç –ò—â–µ–º –≤ {source_name}...")
            
            try:
                results = func(query)
                all_results.extend(results)
                time.sleep(0.2)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞
            except Exception as e:
                st.sidebar.warning(f"–û—à–∏–±–∫–∞ –≤ {source_name}")
    
    progress_bar.empty()
    status_text.empty()
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    seen_titles = set()
    unique_results = []
    for result in all_results:
        if result['title'] not in seen_titles:
            seen_titles.add(result['title'])
            unique_results.append(result)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (—Å–≤–µ–∂–∏–µ —Å–Ω–∞—á–∞–ª–∞)
    unique_results.sort(key=lambda x: x['date'], reverse=True)
    
    return unique_results  # –í–û–ó–í–†–ê–©–ê–ï–ú –í–°–ï –ù–ê–ô–î–ï–ù–ù–´–ï –ù–û–í–û–°–¢–ò

# ========== –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° ==========
# –ü–æ–ª–µ –ø–æ–∏—Å–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏
col1, col2 = st.columns([3, 1])

with col1:
    st.header("üîç –í–≤–µ–¥–∏—Ç–µ —Ç–µ–º—É –¥–ª—è –ø–æ–∏—Å–∫–∞")
    
    if 'search_query' not in st.session_state:
        st.session_state.search_query = ""
    
    search_query = st.text_input(
        "", 
        value=st.session_state.search_query,
        placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: Tim Burton new movie, Wednesday season 2, Beetlejuice sequel...",
        key="main_search_input"
    )

with col2:
    st.markdown("###")
    search_button = st.button("üîé –ù–ê–ß–ê–¢–¨ –ü–û–ò–°–ö –ù–û–í–û–°–¢–ï–ô", type="primary", use_container_width=True)

# –ï—Å–ª–∏ –Ω–∞–∂–∞—Ç–∞ –∫–Ω–æ–ø–∫–∞ –ø–æ–∏—Å–∫–∞
if search_button and search_query:
    with st.spinner(f"üîç –ò—â—É –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{search_query}'..."):
        # –ò—â–µ–º –Ω–æ–≤–æ—Å—Ç–∏
        results = search_all_news(search_query, sources)
        
        if results:
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
            filtered_results = filter_by_time(results, time_filter)
            
            st.success(f"‚úÖ –ù–ê–ô–î–ï–ù–û: {len(filtered_results)} –†–ï–ê–õ–¨–ù–´–• –ù–û–í–û–°–¢–ï–ô!")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            sources_used = set(r['source'] for r in filtered_results)
            st.caption(f"**–ò—Å—Ç–æ—á–Ω–∏–∫–∏:** {', '.join(sources_used)} | **–ü–µ—Ä–∏–æ–¥:** {time_filter} | **–ù–∞–π–¥–µ–Ω–æ –≤—Å–µ–≥–æ:** {len(results)}")
            
            st.markdown("---")
            
            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –í–°–ï –Ω–æ–≤–æ—Å—Ç–∏
            for i, news in enumerate(filtered_results):
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–∫–æ–Ω–∫—É –¥–ª—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                icon = "üì∞"
                if "BBC" in news['source']:
                    icon = "üá¨üáß"
                elif "Guardian" in news['source']:
                    icon = "üóûÔ∏è"
                elif "Variety" in news['source']:
                    icon = "üé¨"
                elif "Deadline" in news['source']:
                    icon = "‚è∞"
                elif "Hollywood" in news['source']:
                    icon = "‚≠ê"
                elif "Google" in news['source']:
                    icon = "üîç"
                elif "IndieWire" in news['source']:
                    icon = "üé•"
                
                # –ö–∞—Ä—Ç–æ—á–∫–∞ –Ω–æ–≤–æ—Å—Ç–∏
                with st.expander(f"{icon} **{news['title']}**", expanded=(i < 5)):  # –ü–µ—Ä–≤—ã–µ 5 –æ—Ç–∫—Ä—ã—Ç—ã
                    col_a, col_b = st.columns([3, 1])
                    
                    with col_a:
                        st.markdown(f"**–ò—Å—Ç–æ—á–Ω–∏–∫:** `{news['source']}`")
                        st.markdown(f"**–î–∞—Ç–∞:** `{news['date'].strftime('%d.%m.%Y %H:%M')}`")
                        
                        if news['summary'] and len(news['summary']) > 50:
                            st.markdown("**–û–ø–∏—Å–∞–Ω–∏–µ:**")
                            st.write(news['summary'])
                    
                    with col_b:
                        st.markdown("")
                        st.markdown("")
                        st.markdown(f"[üìñ –û–¢–ö–†–´–¢–¨ –°–¢–ê–¢–¨–Æ]({news['link']})", unsafe_allow_html=True)
                    
                    # –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å)
                    if news.get('full_text') and len(news['full_text']) > 100:
                        with st.expander("üìÑ –ü–æ–∫–∞–∑–∞—Ç—å –±–æ–ª—å—à–µ —Ç–µ–∫—Å—Ç–∞"):
                            st.write(news['full_text'][:1500] + "..." if len(news['full_text']) > 1500 else news['full_text'])
                
                st.markdown("---")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            st.info(f"""
            **üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û–ò–°–ö–ê:**
            - –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π: **{len(results)}**
            - –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏: **{len(filtered_results)}**
            - –°–∞–º—ã–µ —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏: **{filtered_results[0]['date'].strftime('%d.%m.%Y') if filtered_results else '–Ω–µ—Ç'}**
            - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: **{len(sources_used)}**
            - –°–∞–º–æ–µ —Å—Ç–∞—Ä–æ–µ: **{filtered_results[-1]['date'].strftime('%d.%m.%Y') if len(filtered_results) > 1 else '–Ω–µ—Ç'}**
            """)
            
        else:
            st.error("üòû –ù–ï –ù–ê–ô–î–ï–ù–û –ù–û–í–û–°–¢–ï–ô –ü–û –ó–ê–ü–†–û–°–£.")
            st.info("""
            **üí° –°–û–í–ï–¢–´ –î–õ–Ø –õ–£–ß–®–ï–ì–û –ü–û–ò–°–ö–ê:**
            1. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è** - `"Tim Burton"` –≤–º–µ—Å—Ç–æ `"–¢–∏–º –ë—ë—Ä—Ç–æ–Ω"`
            2. **–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏** - `"Wednesday Netflix"`, `"Wednesday season 2"`, `"Wednesday Addams"`
            3. **–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã–±—Ä–∞–Ω—ã –∏—Å—Ç–æ—á–Ω–∏–∫–∏** –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏
            4. **–†–∞—Å—à–∏—Ä—å—Ç–µ –ø–µ—Ä–∏–æ–¥ –ø–æ–∏—Å–∫–∞** - –≤—ã–±–µ—Ä–∏—Ç–µ "–í—Å–µ –≤—Ä–µ–º—è"
            5. **–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∏—Å–∫–∞—Ç—å –ø–æ–∑–∂–µ** - –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ—è–≤–ª—è—é—Ç—Å—è –ø–æ—Å—Ç–æ—è–Ω–Ω–æ
            
            **–õ—É—á—à–∏–µ –∑–∞–ø—Ä–æ—Å—ã:**
            ‚Ä¢ Wednesday season 2 Netflix
            ‚Ä¢ Beetlejuice 2 release date
            ‚Ä¢ Tim Burton exhibition 2024
            ‚Ä¢ Johnny Depp Burton collaboration
            ‚Ä¢ Monica Bellucci Tim Burton
            """)

# –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –Ω–µ –≤–≤–µ–¥–µ–Ω
elif not search_query or not search_button:
    st.markdown("---")
    
    # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
    col_info1, col_info2 = st.columns(2)
    
    with col_info1:
        with st.expander("üìã –ö–ê–ö –ü–û–õ–¨–ó–û–í–ê–¢–¨–°–Ø", expanded=True):
            st.markdown("""
            ### üîç **–≠–¢–û –†–ï–ê–õ–¨–ù–´–ô –ü–û–ò–°–ö –ù–û–í–û–°–¢–ï–ô**
            
            **–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç:**
            1. **–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å** –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ
            2. **–í—ã–±–µ—Ä–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏** –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏
            3. **–ù–∞–∂–º–∏—Ç–µ "–ù–ê–ß–ê–¢–¨ –ü–û–ò–°–ö"**
            4. **–ü–æ–ª—É—á–∏—Ç–µ –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏**
            
            **–í—Å–µ–≥–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç—Å—è –í–°–ï –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏!**
            
            **–õ—É—á—à–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:**
            ‚Ä¢ BBC News - –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
            ‚Ä¢ The Guardian - –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏
            ‚Ä¢ Variety - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è –∏–Ω–¥—É—Å—Ç—Ä–∏—è
            ‚Ä¢ Deadline - –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –ì–æ–ª–ª–∏–≤—É–¥–∞
            """)
    
    with col_info2:
        with st.expander("üéØ –õ–£–ß–®–ò–ï –ó–ê–ü–†–û–°–´", expanded=True):
            st.markdown("""
            ### **–ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã:**
            
            **–î–ª—è —Ñ–∏–ª—å–º–æ–≤:**
            ‚Ä¢ `Wednesday season 2`
            ‚Ä¢ `Beetlejuice 2`
            ‚Ä¢ `Tim Burton new movie`
            ‚Ä¢ `Burton Netflix project`
            
            **–î–ª—è –∞–∫—Ç–µ—Ä–æ–≤:**
            ‚Ä¢ `Johnny Depp Burton`
            ‚Ä¢ `Jenna Ortega Wednesday`
            ‚Ä¢ `Winona Ryder Beetlejuice`
            ‚Ä¢ `Monica Bellucci Tim`
            
            **–î–ª—è –≤—ã—Å—Ç–∞–≤–æ–∫ –∏ –Ω–æ–≤–æ—Å—Ç–µ–π:**
            ‚Ä¢ `Tim Burton exhibition`
            ‚Ä¢ `Burton art show 2024`
            ‚Ä¢ `Burton interview 2024`
            ‚Ä¢ `New projects 2024`
            """)
    
    # –ü–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ (–ø—Ä–∏–º–µ—Ä)
    st.markdown("---")
    st.subheader("üî• –ß–¢–û –°–ï–ô–ß–ê–° –ò–©–£–¢:")
    
    trending = [
        "üîç Wednesday season 2 Netflix",
        "üîç Beetlejuice 2 release date", 
        "üîç Tim Burton exhibition London",
        "üîç Johnny Depp new movie",
        "üîç Monica Bellucci Tim Burton"
    ]
    
    for trend in trending:
        st.markdown(f"- {trend}")

# –ö–Ω–æ–ø–∫–∞ "–ù–∞ –≥–ª–∞–≤–Ω—É—é"
st.markdown("---")
if st.button("üè† –ù–ê –ì–õ–ê–í–ù–£–Æ –°–¢–†–ê–ù–ò–¶–£", use_container_width=True, type="secondary"):
    st.markdown("""
    <div style='text-align: center; padding: 20px; background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); border-radius: 10px;'>
        <h4 style='color: #f0e68c;'>–ü–ï–†–ï–ô–¢–ò –ù–ê –ì–õ–ê–í–ù–£–Æ –°–¢–†–ê–ù–ò–¶–£ –ü–†–û–ï–ö–¢–ê</h4>
        <a href='https://quixotic-shrimp-ea9.notion.site/9aabb68bd7004965819318e32d8ff06e?v=2b4a0ca7844a80d6aa8a000c6a7e5272' 
           target='_blank' 
           style='color: #ff6b6b; text-decoration: none; font-weight: bold; font-size: 18px; background: #0f3460; padding: 10px 20px; border-radius: 5px; display: inline-block; margin: 10px;'>
           üöÄ –û–¢–ö–†–´–¢–¨ –ì–õ–ê–í–ù–£–Æ
        </a>
    </div>
    """, unsafe_allow_html=True)

# –§—É—Ç–µ—Ä
st.markdown("---")
st.caption(f"üé¨ –†–ï–ê–õ–¨–ù–´–ô –ü–û–ò–°–ö –ù–û–í–û–°–¢–ï–ô | –û–ë–ù–û–í–õ–ï–ù–û: {datetime.now().strftime('%d.%m.%Y %H:%M')} | –í–°–ï–ì–î–ê –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–û–õ–ò–ß–ï–°–¢–í–û –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
